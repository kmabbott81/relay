"""Unit tests for TASK C cross-encoder reranker

Tests cover:
- Cross-encoder initialization
- Basic reranking functionality
- Circuit breaker (timeout handling)
- Feature flag (RERANK_ENABLED)
- Latency validation (p95 < 150ms for 24 candidates)
- Graceful fallback on GPU unavailability
"""

import asyncio
import os
import time
from unittest.mock import patch

import pytest

# Allow tests to run even without GPU/sentence-transformers
pytest_plugins = ("pytest_asyncio",)


class TestCrossEncoderInit:
    """Model initialization tests"""

    @pytest.mark.skip(reason="Requires GPU/torch - integration test only")
    def test_get_cross_encoder_loads_model(self):
        """Cross-encoder model loads on first call"""
        from relay_ai.platform.security.memory.rerank import get_cross_encoder

        model = get_cross_encoder()
        assert model is not None

    @pytest.mark.skip(reason="Requires GPU/torch - integration test only")
    def test_get_cross_encoder_caches_model(self):
        """Subsequent calls return cached instance"""
        from relay_ai.platform.security.memory.rerank import get_cross_encoder

        model1 = get_cross_encoder()
        model2 = get_cross_encoder()
        assert model1 is model2


class TestReranking:
    """Semantic reranking quality and latency tests"""

    @pytest.mark.asyncio
    async def test_rerank_empty_candidates(self):
        """Empty candidates returns empty list"""
        from relay_ai.platform.security.memory.rerank import rerank

        result = await rerank("query", [])
        assert result == []

    @pytest.mark.asyncio
    async def test_rerank_single_candidate(self):
        """Single candidate returns as-is"""
        from relay_ai.platform.security.memory.rerank import RerankedResult, rerank

        result = await rerank("query", ["candidate"])
        assert len(result) == 1
        assert isinstance(result[0], RerankedResult)
        assert result[0].candidate == "candidate"

    @pytest.mark.skip(reason="Requires GPU/torch - integration test only")
    @pytest.mark.asyncio
    async def test_rerank_sorts_by_relevance(self):
        """Reranking sorts candidates by relevance"""
        from relay_ai.platform.security.memory.rerank import rerank

        query = "How do I reset my password?"
        candidates = [
            "Contact us for support",  # Irrelevant
            "Reset your password here",  # Relevant
            "Security best practices",  # Somewhat relevant
        ]

        result = await rerank(query, candidates)

        # Most relevant should be first
        assert result[0].candidate == "Reset your password here"

    @pytest.mark.skip(reason="Requires GPU/torch - integration test only")
    @pytest.mark.asyncio
    async def test_rerank_latency_budget(self):
        """p95 latency < 150ms for 24 candidates (PERFORMANCE GATE)"""
        from relay_ai.platform.security.memory.rerank import rerank

        query = "test query"
        candidates = [f"candidate {i}" for i in range(24)]

        latencies = []
        for _ in range(100):
            start = time.time()
            await rerank(query, candidates)
            latencies.append((time.time() - start) * 1000)

        latencies.sort()
        p95 = latencies[95]

        assert p95 < 150, f"p95 latency {p95}ms exceeds budget 150ms"


class TestCircuitBreaker:
    """Timeout handling and fail-open behavior"""

    @pytest.mark.asyncio
    async def test_rerank_timeout_returns_ann_order(self):
        """Timeout exceeded â†’ returns ANN order (fail-open)"""
        from relay_ai.platform.security.memory.rerank import rerank

        # Mock get_cross_encoder to hang
        with patch("src.memory.rerank.get_cross_encoder") as mock_get:

            async def slow_operation():
                await asyncio.sleep(10)  # Hang for 10s

            mock_get.side_effect = Exception("Model loading failed")

            candidates = ["candidate_1", "candidate_2", "candidate_3"]
            result = await rerank("query", candidates, timeout_ms=100)

            # Should return ANN order (original order)
            assert len(result) == 3
            assert result[0].candidate == "candidate_1"

    @pytest.mark.asyncio
    async def test_circuit_breaker_threshold(self):
        """Circuit breaker activates at correct timeout"""
        from relay_ai.platform.security.memory.rerank import rerank

        candidates = ["candidate_1", "candidate_2"]

        # Timeout of 1ms should definitely trigger (unless machine is extremely fast)
        result = await rerank("query", candidates, timeout_ms=1)

        # Should return something (ANN order)
        assert len(result) >= 0  # May timeout or complete


class TestFeatureFlag:
    """RERANK_ENABLED feature flag toggle"""

    @pytest.mark.asyncio
    async def test_maybe_rerank_enabled(self):
        """maybe_rerank reranks when enabled"""
        os.environ["RERANK_ENABLED"] = "true"

        # Reload module to pick up env var
        import importlib

        import src.memory.rerank

        importlib.reload(src.memory.rerank)

        from relay_ai.platform.security.memory.rerank import maybe_rerank

        candidates = ["candidate_1", "candidate_2"]
        result = await maybe_rerank("query", candidates)

        # Should return list (reranking attempted)
        assert isinstance(result, list)
        assert len(result) == 2

    @pytest.mark.asyncio
    async def test_maybe_rerank_disabled(self):
        """maybe_rerank no-ops when disabled"""
        os.environ["RERANK_ENABLED"] = "false"

        # Reload module to pick up env var
        import importlib

        import src.memory.rerank

        importlib.reload(src.memory.rerank)

        from relay_ai.platform.security.memory.rerank import maybe_rerank

        candidates = ["candidate_1", "candidate_2"]
        result = await maybe_rerank("query", candidates)

        # Should return candidates unchanged
        assert result == candidates


class TestMetrics:
    """Metrics collection and reporting"""

    def test_get_rerank_metrics(self):
        """Metrics dict contains required fields"""
        from relay_ai.platform.security.memory.rerank import get_rerank_metrics

        metrics = get_rerank_metrics()

        assert "rerank_enabled" in metrics
        assert "model_loaded" in metrics
        assert "device" in metrics
        assert "model_name" in metrics
        assert "timeout_ms" in metrics

    def test_metrics_device_detection(self):
        """Metrics reports correct device"""
        from relay_ai.platform.security.memory.rerank import get_rerank_metrics

        metrics = get_rerank_metrics()

        # Device should be cuda or cpu
        assert metrics["device"] in ["cuda", "cpu"]


class TestErrorHandling:
    """Error handling and graceful degradation"""

    @pytest.mark.asyncio
    async def test_rerank_with_model_error(self):
        """Model errors return ANN order (fail-open)"""
        from relay_ai.platform.security.memory.rerank import rerank

        candidates = ["candidate_1", "candidate_2"]

        with patch("src.memory.rerank.get_cross_encoder") as mock:
            mock.side_effect = RuntimeError("Model not found")

            result = await rerank("query", candidates)

            # Should return ANN order
            assert len(result) == 2
            assert result[0].candidate == "candidate_1"

    @pytest.mark.asyncio
    async def test_maybe_rerank_error_handling(self):
        """maybe_rerank catches all errors and returns ANN order"""
        from relay_ai.platform.security.memory.rerank import maybe_rerank

        candidates = ["candidate_1", "candidate_2"]

        with patch("src.memory.rerank.rerank") as mock:
            mock.side_effect = Exception("Unexpected error")

            result = await maybe_rerank("query", candidates)

            # Should return ANN order
            assert result == candidates


class TestRerankedResult:
    """RerankedResult data structure"""

    def test_reranked_result_creation(self):
        """RerankedResult can be created and accessed"""
        from relay_ai.platform.security.memory.rerank import RerankedResult

        result = RerankedResult("test candidate", 0.95, 5)

        assert result.candidate == "test candidate"
        assert result.score == 0.95
        assert result.original_index == 5

    def test_reranked_result_repr(self):
        """RerankedResult has readable repr"""
        from relay_ai.platform.security.memory.rerank import RerankedResult

        result = RerankedResult("test candidate text is long", 0.95, 5)
        repr_str = repr(result)

        assert "RerankedResult" in repr_str
        assert "0.950" in repr_str


# ============================================================================
# INTEGRATION TEST MARKERS (Skip by default, run with GPU)
# ============================================================================


def pytest_configure(config):
    """Register custom marker for GPU tests"""
    config.addinivalue_line("markers", "gpu: mark test as requiring GPU/torch (deselect with '-m \"not gpu\"')")


if __name__ == "__main__":
    # Run with: pytest tests/memory/test_rerank.py -v -m "not gpu"
    # Run with GPU: pytest tests/memory/test_rerank.py -v
    pytest.main([__file__, "-v", "-m", "not gpu"])
